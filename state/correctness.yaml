correct_state:
  outputs:
    context.correct_count: '{{context.correct_count + 1}}'
    context.question_idx: '{{(context.question_idx + 1) % context.questions.length}}'
    context.memory: '{{[]}}'
  render:
    buttons:
    - content: Continue
      description: continue to play
      on_click: continue
    - content: Chat
      description: Go to free chat mod
      on_click: chat_state
    text: '## {{context.questions[context.question_idx][''congrats'']}}
      \n You have get the correct answer.
      \n `{{context.reply}}`,
      \n Your prompt is: `{{context.your_answer}}`
      \n correctness: `{{context.is_correct}}`
      \n context.correct_count: `{{context.correct_count}}`
      \n next level: `{{context.question_idx + 1}}`
      \n\n Click Continue or type anything go to next level.'
  transitions:
    CHAT: continue_state
incorrect_state:
  outputs:
    context.memory: '{{[]}}'
  render:
    buttons:
    - content: Continue
      description: continue play
      on_click: continue
    - content: Chat
      description: Go to free chat mod
      on_click: chat_state
    text: '## {{context.questions[context.question_idx][''encourage'']}}
      \n Your input is: `{{context.your_answer}}`,
      \n LLM generated: `{{context.reply}}`, which not meet the requirments.
      \n we expect: `{{context.correct_answer}}`
      \n Judge Replied with `{{context.judge_reply}}`
      \n correctness: `{{context.is_correct}}`
      \n context.correct_count: `{{context.correct_count}}`
      \n current level: `{{context.question_idx + 1}}`
      \n\n Click Continue or type anything to try again.
      \n\n Pseudocode: `{{context.judge_prompt}}`'
  transitions:
    CHAT: continue_state
